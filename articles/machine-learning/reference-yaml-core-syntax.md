---
title: 'CLI (v2) core YAML syntax'
titleSuffix: Azure Machine Learning
description: Overview CLI (v2) core YAML syntax.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference

author: mx-iao
ms.author: minxia
ms.date: 10/21/2021
ms.reviewer: laobri
---

# CLI (v2) core YAML syntax

Every Azure Machine Learning entity has a schematized YAML representation. You can create a new entity from a YAML configuration file with a `.yml` or `.yaml` extension.

This article provides an overview of core syntax concepts you will encounter while configuring these YAML files.

[!INCLUDE [preview disclaimer](../../includes/machine-learning-preview-generic-disclaimer.md)]

## Referencing an Azure ML entity

Azure ML provides a reference syntax (consisting of a shorthand and longhand format) for referencing an existing Azure ML entity when configuring a YAML file. For example, you can reference an existing registered environment in your workspace to use at the environment for a job.

### Shorthand

The shorthand syntax consists of the following:

* For assets: `azureml:<asset-name>:<asset-version>`
* For resources: `azureml:<resource-name>`

Azure ML will resolve this reference to the specified asset or resource in the workspace.

### Longhand

The longhand syntax consists of the `azureml:` prefix plus the ARM resource ID of the entity:

```
azureml:/subscriptions/<subscription-id>/resourceGroups/<resource-group>/providers/Microsoft.MachineLearningServices/workspaces/<workspace-name>/environments/<environment-name>/versions/<environment-version>
```

## Azure ML data reference URI

Azure ML offers a convenience data reference URI format to point to data in an Azure storage service. This can be used for scenarios where you need to specify a cloud storage location in your YAML file, such as creating an Azure ML model from file(s) in storage, or pointing to data to pass as input to a job.

To use this data URI format, the storage service you want to reference must first be registered as a datastore in your workspace. Azure ML will handle the data access using the credentials you provided during datastore creation.

The format consists of a datastore in the current workspace and the path on the datastore to the file or folder you want to point to:

```
azureml://datastores/<datastore-name>/paths/<path-on-datastore>/
```

For example:

* `azureml://datastores/workspaceblobstore/paths/example-data/`
* `azureml://datastores/workspaceblobstore/paths/example-data/iris.csv`

In addition to the Azure ML data reference URI, Azure ML also supports the following direct storage URI protocols: `https`, `wasbs`, `abfss`, and `adl`, as well as public `http` and `https` URIs.

## Expression syntax for configuring Azure ML jobs and components

v2 job and component YAML files allow for the use of expressions to bind to contexts for different scenarios. The essential use case is using an expression for a value that might not be known at the time of authoring the configuration, but must be resolved at runtime.

Use the following syntax to tell Azure ML to evaluate an expression rather than treat it as a string:

`${{ <expression> }}`

The supported scenarios are covered below.

### Parameterizing the `command` with the `inputs` and `outputs` contexts of a job

You can specify literal values, URI paths, and Azure ML datasets as inputs to a job. The `command` can then be parameterized with references to those input(s) using the `${{inputs.<input-name>}}` syntax. References to literal inputs will get resolved to the literal value at runtime, while references to data URI or Azure ML dataset inputs will get resolved to the download path or mount path (depending on the `mode` specified).

Likewise, outputs to the job can also be referenced in the `command`. For each named output specified in the `outputs` dictionary, Azure ML will autogenerate an output location on the default datastore where you can write files to. The output location for each named output is based on the following templatized path: `<default-datastore>/azureml/<job-name>/<output-name>/`. Parameterizing the `command` with the `${{outputs.<output-name>}}` syntax will resolve that reference to the autogenerated path, so that your script can write files to that location from the job.

In the example below for a command job YAML file, the `command` is parameterized with two inputs, a literal input and a URI input, and one output. At runtime, the `${{inputs.learning_rate}}` expression will resolve to `0.01`, and the `${{inputs.iris}}` expression will resolve to the download path of the `iris.csv` file. `${{outputs.model_dir}}` will resolve to the mount path of the autogenerated output location.

```yaml
$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json
code:
  local_path: ./src
command: python train.py --lr ${{inputs.learning_rate}} --training-data ${{inputs.iris}} --model-dir ${{outputs.model_dir}}
environment: azureml:AzureML-Minimal:1
compute: azureml:cpu-cluster
inputs:
  learning_rate: 0.01
  iris:
    file: https://azuremlexamples.blob.core.windows.net/datasets/iris.csv
    mode: download
outputs:
  model_dir:
```

### Parameterizing the `command` with the `search_space` context of a sweep job

You will also use this expression syntax when performing hyperparameter tuning via a sweep job, since the actual values of the hyperparameters are not known during job authoring time. When you run a sweep job, Azure ML will select hyperparameter values for each trial based on the `search_space`. In order to access those values in your training script, you must pass them in via the script's command-line arguments. To do so, use the `${{search_space.<hyperparameter>}}` syntax in the `trial.command`.

In the example below for a sweep job YAML file, the `${{search_space.learning_rate}}` and `${{search_space.boosting}}` references in `trial.command` will resolve to the actual hyperparameter values selected for each trial when the trial job is submitted for execution.

```yaml
$schema: https://azuremlschemas.azureedge.net/latest/sweepJob.schema.json
type: sweep
sampling_algorithm: random
search_space:
  learning_rate:
    type: uniform
    min_value: 0.01
    max_value: 0.9
  boosting:
    type: choice
    values: ["gbdt", "dart"]
objective:
  goal: minimize
  primary_metric: test-multi_logloss
trial:
  code: 
    local_path: src 
  command: >-
    python train.py 
    --training-data ${{inputs.iris}}
    --lr ${{search_space.learning_rate}}
    --boosting ${{search_space.boosting}}
  environment: azureml:AzureML-Minimal:1
inputs:
  iris:
    file: https://azuremlexamples.blob.core.windows.net/datasets/iris.csv
    mode: download
compute: azureml:cpu-cluster
```

### Binding inputs and outputs between steps in a pipeline job

Expressions are also used for binding inputs and outputs between steps in a pipeline job. For example, you can bind the input of one job (job #2) in a pipeline to the output of another job (job #1). This usage will signal to Azure ML the dependency flow of the pipeline graph, and job #2 will get executed after job #1, since the output of job #1 is required as an input for job #2.

For a pipeline job YAML file, the `inputs` and `outputs` sections of each child job are evaluated within the parent context (the top-level pipeline job). The `command`, on the other hand, will resolve to the current context (the child job).

There are two ways to bind inputs and outputs in a pipeline job:

**1) Bind to the top-level inputs and outputs of the pipeline job**

You can bind the inputs or outputs of a child job to the inputs/outputs of the top-level parent pipeline job using the following syntax: `${{inputs.<input-name>}}` or `${{outputs.<output-name>}}`. This reference resolves to the parent context; hence the top-level inputs/outputs. 

In the example below, the output (`model_dir`) of the final `train` step is bound to the top-level pipeline job output via `${{outputs.trained_model}}`

**2) Bind to the inputs and outputs of another child job (step)**

To bind the inputs/outputs of one step to the inputs/outputs of another step, use the following syntax: `${{jobs.<step-name>.inputs.<input-name>}}` or `${{jobs.<step-name>.outputs.<outputs-name>}}`. Again, this reference resolves to the parent context, so the context starts with `jobs.<step-name>`.

In the example below, the input (`clean_data`) of the `train` step is bound to the output (`prep_data`) of the `prep` step via `${{jobs.prep.outputs.prep_data}}`. The prepared data from the `prep` step will be used as the training data for the `train` step.

On the other hand, the context references within the `command` properties will resolve to the current context. For example, the `${{inputs.raw_data}}` reference in the `prep` step's `command` will resolve to the inputs of the current context, which is the `prep` child job. The lookup will be done on `prep.inputs`, so an input named `raw_data` must be defined there.

```yaml
$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json
type: pipeline
inputs:
outputs:
  trained_model:
jobs:
  prep:
    type: command
    inputs:
      raw_data:
        folder:
        mode: rw_mount
    outputs:
      prep_data: 
        mode: upload
    code:
      local_path: src/prep
    environment: azureml:AzureML-Minimal:1
    command: >-
      python prep.py 
      --raw-data ${{inputs.raw_data}} 
      --prep-data ${{outputs.prep_data}}
    compute: azureml:cpu-cluster
  train:
    type: command
    inputs: 
      clean_data: ${{jobs.prep.outputs.prep_data}}
    outputs:
      model_dir: $${{outputs.trained_model}}
    code: 
      local_path: src/train
    environment: azureml:AzureML-Minimal:1
    compute: azureml:gpu-cluster
    command: >-
      python train.py 
      --training-data ${{inputs.clean_data}} 
      --model-output ${{outputs.model_dir}}
```

### Parameterizing the `command` with the `inputs` and `outputs` contexts of a component

Similar to the `command` for a job, the `command` for a component can also be parameterized with references to the `inputs` and `outputs` contexts. In this case the reference is to the component's inputs and outputs. When the component is run in a job, Azure ML will resolve those references to the job runtime input and output values specified for the respective component inputs and outputs. Below is an example of using the context syntax for a command component YAML specification.

```yaml
$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json
type: command
code:
  local_path: ./src
command: python train.py --lr ${{inputs.learning_rate}} --training-data ${{inputs.iris}} --model-dir ${{outputs.model_dir}}
environment: azureml:AzureML-Minimal:1
inputs:
  learning_rate:
    type: number
    default: 0.01
    optional: true
  iris:
    type: path
outputs:
  model_dir:
    type: path
```

## Next steps

* [Install and use the CLI (v2)](how-to-configure-cli.md)
* [Train models with the CLI (v2)](how-to-train-cli.md)
* [CLI (v2) YAML schemas](reference-yaml-overview.md)
